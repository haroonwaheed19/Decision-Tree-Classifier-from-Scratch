{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNbqBg6gYBDhzwOxC6bKqcg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/haroonwaheed19/Decision-Tree-Classifier-from-Scratch/blob/main/Decision_Tree_Classifier_from_Scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AANMTuXLBbOq"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Node:\n",
        "  def __init__(self,feature_index=None,threshold=None,left=None,right=None,info_gain=None,value=None):\n",
        "    #for decision node\n",
        "    self.feature_index = feature_index\n",
        "    self.threshold = threshold\n",
        "    self.left = left\n",
        "    self.right = right\n",
        "    self.info_gain = info_gain\n",
        "\n",
        "    #for leaf node\n",
        "    self.value = value"
      ],
      "metadata": {
        "id": "GwHa4UxPCJcb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecisionTreeClassifier:\n",
        "  #Constructor\n",
        "  def __init__(self,min_samples_split=2,max_depth=2):\n",
        "    #initializing the root of tree\n",
        "    self.root = None\n",
        "\n",
        "    #stopping conditions for our model\n",
        "    self.min_samples_split = min_samples_split\n",
        "    self.max_depth = max_depth\n",
        "\n",
        "  #Model training function\n",
        "  def fit(self,X,Y):\n",
        "    dataset = np.concatenate((X,Y),axis=1)\n",
        "    self.root = self.build_tree(dataset)\n",
        "\n",
        "  #helper function to build the tree\n",
        "  def build_tree(self,dataset,curr_depth=0):\n",
        "    X,Y = dataset[:,:-1],dataset[:,-1]\n",
        "\n",
        "    num_samples,num_features = np.shape(X)\n",
        "\n",
        "    #split untill stopping conditions are met\n",
        "    if num_samples >= self.min_samples_split and curr_depth <= self.max_depth:\n",
        "      #finding the best split for division of dataset\n",
        "      best_split = self.get_best_split(dataset,num_samples,num_features)\n",
        "      #checking if info_gain is positive or not\n",
        "      if best_split[\"info_gain\"] > 0:\n",
        "        #recursively create left tree\n",
        "        left_subtree = self.build_tree(best_split[\"dataset_left\"],curr_depth + 1)\n",
        "        #recursively create right tree\n",
        "        right_subtree = self.build_tree(best_split[\"dataset_right\"],curr_depth + 1)\n",
        "        #return decision node\n",
        "        return Node(best_split[\"feature_index\"],best_split[\"threshold\"],left_subtree,right_subtree,best_split[\"info_gain\"])\n",
        "    #calculate leaf node\n",
        "    leaf_value = self.calculate_leaf_value(Y)\n",
        "\n",
        "    #return leaf node\n",
        "    return Node(value=leaf_value)\n",
        "\n",
        "  #calculate leaf function\n",
        "  def calculate_leaf_value(self,Y):\n",
        "    Y = list(Y)\n",
        "    return max(Y,key=Y.count)\n",
        "\n",
        "  #get best split helper function\n",
        "  def get_best_split(self,dataset,num_samples,num_features):\n",
        "    #empty directory to store best split\n",
        "    best_split = {}\n",
        "    #initialize with negative infinity\n",
        "    max_info_gain = -float(\"inf\")\n",
        "\n",
        "    #looping through over the features\n",
        "    for feature_index in range(num_features):\n",
        "      feature_values = dataset[:,feature_index]\n",
        "      possible_thresholds = np.unique(feature_values)\n",
        "\n",
        "      #looping through over the possible thresholds\n",
        "      for threshold in possible_thresholds:\n",
        "        #getting the left-node and right-node data\n",
        "        #get current split\n",
        "        dataset_left,dataset_right = self.split(dataset,feature_index,threshold)\n",
        "\n",
        "        #checking if childs are not empty\n",
        "        if len(dataset_left) > 0 and len(dataset_right) > 0:\n",
        "          y,left_y,right_y = dataset[:,-1],dataset_left[:,-1],dataset_right[:,-1]\n",
        "\n",
        "        #calcualting the information gain\n",
        "        current_info_gain = self.information_gain(y,left_y,right_y,\"gini\")\n",
        "\n",
        "        #updating the best split directory if the current gain is higher\n",
        "        if(current_info_gain > max_info_gain):\n",
        "          best_split[\"feature_index\"] = feature_index\n",
        "          best_split[\"threshold\"] = threshold\n",
        "          best_split[\"dataset_left\"] = dataset_left\n",
        "          best_split[\"dataset_right\"] = dataset_right\n",
        "          best_split[\"info_gain\"] = current_info_gain\n",
        "          max_info_gain = current_info_gain\n",
        "\n",
        "    #return best split\n",
        "    return best_split\n",
        "\n",
        "\n",
        "  #split function for dataset\n",
        "  def split(self,dataset,feature_index,threshold):\n",
        "    dataset_left = np.array([row for row in dataset if row[feature_index] <= threshold])\n",
        "\n",
        "    dataset_right = np.array([row for row in dataset if row[feature_index] > threshold])\n",
        "    return dataset_left,dataset_right\n",
        "\n",
        "  #information gain function\n",
        "  def information_gain(self,parent,l_child,r_child,mode=\"entropy\"):\n",
        "    weight_l = len(l_child) / len(parent)\n",
        "    weight_r = len(r_child) / len(parent)\n",
        "\n",
        "    if mode == \"gini\":\n",
        "      gain = self.gini_index(parent) - (weight_l * self.gini_index(l_child) + weight_r * self.gini_index(r_child))\n",
        "    else:\n",
        "      gain = self.entropy(parent) - (weight_l * self.entropy(l_child) + weight_r * self.entropy(r_child))\n",
        "    return gain\n",
        "\n",
        "  #entropy function\n",
        "  def entropy(self,y):\n",
        "    class_labels = np.unique(y)\n",
        "    entropy = 0\n",
        "    for cls in class_labels:\n",
        "      p_cls = len(y[y == cls]) / len(y)\n",
        "      entropy += -p_cls * np.log2(p_cls)\n",
        "    return entropy\n",
        "\n",
        "  #Gini Impurity\n",
        "  def gini_index(self,y):\n",
        "    class_labels = np.unique(y)\n",
        "    gini = 0\n",
        "    for cls in class_labels:\n",
        "      p_cls = len(y[y == cls]) / len(y)\n",
        "      gini += p_cls ** 2\n",
        "    return 1 - gini\n",
        "\n",
        "\n",
        "  #Print Tree\n",
        "  def print_tree(self,tree=None,indent=\" \"):\n",
        "    if not tree:\n",
        "      tree = self.root\n",
        "\n",
        "    if tree.value is not None:\n",
        "      print(tree.value)\n",
        "    else:\n",
        "      print(\"X_\"+str(tree.feature_index),\"<=\",tree.threshold,\":\",tree.info_gain)\n",
        "      print(\"%sleft:\" % (indent),end=\"\")\n",
        "      self.print_tree(tree.left,indent + indent)\n",
        "      print(\"%sright:\" % (indent),end=\"\")\n",
        "      self.print_tree(tree.right,indent + indent)\n",
        "\n",
        "\n",
        "  #predict function\n",
        "  def predict(self,X):\n",
        "    predictions = [self.make_prediction(x,self.root) for x in X]\n",
        "    return predictions\n",
        "\n",
        "  #Make prediction function\n",
        "  def make_prediction(self,x,tree):\n",
        "    if tree.value != None:\n",
        "      return tree.value\n",
        "\n",
        "    feature_val = x[tree.feature_index]\n",
        "    if feature_val <= tree.threshold:\n",
        "      return self.make_prediction(x,tree.left)\n",
        "    else:\n",
        "      return self.make_prediction(x,tree.right)"
      ],
      "metadata": {
        "id": "dxlE-fyEKbZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q1X2pl1Hi0YR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}